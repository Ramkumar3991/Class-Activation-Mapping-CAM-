{
    "source": [
    "#importing Libraries\n",
    "import tensorflow as tf\n",
    "from gradcam_plus import grad_cam_plus\n",
    "from utils import pre_process_input,evaluate_metrics,final_metrics\n",
    "\n",
    "#hyper_parameters\n",
    "No_of_images = 2500\n",
    "batch_size = 100\n",
    "img_size = 224\n",
    "layer_id = [-6] #layer id to consider for gradcam++ computation\n",
    "img_dir = '/Input_data'\n",
    "model_name = 'vgg16'\n",
    "\n",
    "#variables for loop and metrics evalaution\n",
    "so_ba = 0\n",
    "sum_i = count_Ioc = sum_un = count_Doc = 0\n",
    "\n",
    "#number of batches taken to evaluate\n",
    "steps = int(No_of_images / batch_size)\n",
    "\n",
    "#images_in_batch\n",
    "batch_holder,images = pre_process_input(No_of_images,img_dir,img_size,model_name)\n",
    "\n",
    "#pre-trained vgg16 model\n",
    "model = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=True, weights='imagenet',classes=1000)\n",
    "\n",
    "#gradcam++ computation and its metrics.\n",
    "for i in range(steps):\n",
    "    print(i)\n",
    "    gradcam_plus_batch,original_images,batch_holder_image = grad_cam_plus(batch_holder,images,model,layer_id,batch_size,so_ba,img_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
